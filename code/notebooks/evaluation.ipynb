{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from src.train_pm import Dataset, double_conv, LeUNet, StandardNet, EnsembleNet, EPAPLN, ResNetUNet, EnsembleLeUNet\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from src.preprocessing.trans_func import *\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../test_data.csv')\n",
    "files = list(data['filename'])\n",
    "ppm = list(data['ppm'])\n",
    "ids = [i for i in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LeUNet()\n",
    "# model = torch.nn.DataParallel(model).cuda()\n",
    "# model.load_state_dict(torch.load(\"../src/model_pm_train.pth\"),strict=False) # on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNetUNet()\n",
    "# model = torch.nn.DataParallel(model).cuda()\n",
    "# model.load_state_dict(torch.load(\"../src/resnetunet_pm_train.pth\"),strict=False) # on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = StandardNet('resnet50').cuda()\n",
    "# model.load_state_dict(torch.load(\"../src/resnet50_pm_train.pth\"),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = StandardNet('vgg16').cuda()\n",
    "# model.load_state_dict(torch.load(\"../src/vgg16_pm_train.pth\"),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = StandardNet('inception_v3').cuda()\n",
    "# model.load_state_dict(torch.load(\"../src/inception_pm_train.pth\"),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EPAPLN().cuda()\n",
    "model.load_state_dict(torch.load(\"../src/epapln_pm_train.pth\"),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EnsembleNet().cuda()\n",
    "# model.load_state_dict(torch.load(\"../src/ensemble_pm_train.pth\"),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EnsembleLeUNet().cuda()\n",
    "# model.load_state_dict(torch.load(\"../src/ensembleleunet_pm_train.pth\"),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(ids, files, ppm, transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor(),transforms.Normalize(mean=[0.5231, 0.5180, 0.5115],std=[0.2014, 0.2018, 0.2100]),])) # normalize\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "preds = []\n",
    "for x, y in loader:\n",
    "    y = y.float()\n",
    "    x = x.cuda(non_blocking=True)\n",
    "    y = y.cuda(non_blocking=True)\n",
    "\n",
    "    x_var = torch.autograd.Variable(x)\n",
    "    y_var = torch.autograd.Variable(y)\n",
    "\n",
    "    yhat = model(x_var).squeeze()\n",
    "    actual += [y_var.cpu().detach().numpy()]\n",
    "    preds += [yhat.cpu().detach().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = np.concatenate(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = np.array(preds)-np.array(actual)\n",
    "plt.hist(err_test, bins=20,range=(-300,300))\n",
    "plt.title(\"Error b/w prediction and actual PM-2.5 \\nfor test set (without outliers)\")\n",
    "plt.xlabel('err')\n",
    "plt.ylabel('# examples')\n",
    "plt.savefig('err_full.png')\n",
    "plt.show()\n",
    "print(np.mean(err_test))\n",
    "print(np.std(err_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.abs(err_test), bins=20)\n",
    "plt.title(\"Absolute error b/w prediction and actual PM-2.5 \\nfor test set (with outliers)\")\n",
    "plt.xlabel('err')\n",
    "plt.ylabel('# examples')\n",
    "plt.savefig('err_val.png')\n",
    "plt.show()\n",
    "print(np.mean(np.abs(err_test)))\n",
    "print(np.std(np.abs(err_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(np.abs(err_train), bins=20)\n",
    "# plt.title(\"Absolute error b/w prediction and actual PM-2.5 \\nfor test set (with outliers)\")\n",
    "# plt.xlabel('err')\n",
    "# plt.ylabel('# examples')\n",
    "# plt.savefig('err_val.png')\n",
    "# plt.show()\n",
    "# print(np.mean(np.abs(err_train)))\n",
    "# print(np.std(np.abs(err_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_china = []\n",
    "id_delhi = []\n",
    "for index, row in data.iterrows():\n",
    "    filename = row['filename']\n",
    "    if filename.startswith('Shanghai1') or filename.startswith('Shanghai2') or filename.startswith('Shanghai3') or filename.startswith('Beijing'):\n",
    "        id_china.append(index)\n",
    "    else:\n",
    "        id_delhi.append(index)\n",
    "\n",
    "print(len(id_china))\n",
    "print(len(id_delhi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_china = np.abs(err_test[np.array(id_china)]) #err_val,err?\n",
    "err_delhi = np.abs(err_test[np.array(id_delhi)])\n",
    "plt.hist(err_china, bins=20)\n",
    "plt.title(\"Absolute error b/w prediction and actual PM-2.5 \\nfor single-scene test set (with outliers)\")\n",
    "plt.xlabel('err')\n",
    "plt.ylabel('# examples')\n",
    "plt.savefig('err_china.png')\n",
    "plt.show()\n",
    "print(np.mean(err_china))\n",
    "print(np.std(err_china))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(err_delhi, bins=20)\n",
    "plt.title(\"Absolute error b/w prediction and actual PM-2.5 \\nfor multiple-scene delhi test set (with outliers)\")\n",
    "plt.xlabel('err')\n",
    "plt.ylabel('# examples')\n",
    "plt.savefig('err_delhi.png')\n",
    "plt.show()\n",
    "print(np.mean(err_delhi))\n",
    "print(np.std(err_delhi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(err_test[np.array(id_delhi)], bins=40)\n",
    "plt.title(\"Error b/w prediction and actual PM-2.5 \\nfor multiple-scene delhi test set (with outliers)\")\n",
    "plt.xlabel('err')\n",
    "plt.ylabel('# examples')\n",
    "plt.savefig('err_delhi.png')\n",
    "plt.show()\n",
    "print(np.mean(err_test[np.array(id_delhi)]))\n",
    "print(np.std(err_test[np.array(id_delhi)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_delhi = actual[np.array(id_delhi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_delhi = preds[np.array(id_delhi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_p = 0\n",
    "for i in range(len(id_delhi)):\n",
    "    if((preds_delhi[i]<actual_delhi[i]+25) and (preds_delhi[i]>actual_delhi[i]-25)):\n",
    "        correct_p+=1\n",
    "print(correct_p, len(id_delhi), correct_p*1.0/len(id_delhi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_p = 0\n",
    "for i in range(len(id_delhi)):\n",
    "    if((preds_delhi[i]<actual_delhi[i]+50) and (preds_delhi[i]>actual_delhi[i]-50)):\n",
    "        correct_p+=1\n",
    "print(correct_p, len(id_delhi), correct_p*1.0/len(id_delhi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pollution Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = pd.read_csv(\"/scratch/ab9738/pollution_img/govdata/locations.csv\")\n",
    "location_df = location_df.drop([\"source\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df['Lat-Lon'] = location_df['lat'].apply(str) +','+ location_df['lon'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = location_df.drop(['lat', 'lon'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding UP Sensor Locations\n",
    "location_df.loc[len(location_df)] = ['SanjayNagar_UPPCP', '28.685382,77.453839']\n",
    "location_df.loc[len(location_df)] = ['Indirapuram_UPPCP', '28.646233,77.358075']\n",
    "location_df.loc[len(location_df)] = ['Vasundhara_UPPCP', '28.6603346,77.3572563']\n",
    "location_df.loc[len(location_df)] = ['Loni_UPPCP', '28.757294,77.278792']\n",
    "location_df.loc[len(location_df)] = ['NoidaSector62_IMD', '28.6245479,77.3577104']\n",
    "location_df.loc[len(location_df)] = ['NoidaSector116_UPPCP', '28.56912141,77.3939069']\n",
    "location_df.loc[len(location_df)] = ['KnowledgeParkV_UPPCP', '28.55856132,77.45445483']\n",
    "location_df.loc[len(location_df)] = ['KnowledgeParkIII_UPPCP', '28.47250249,77.48179193']\n",
    "location_df.loc[len(location_df)] = ['NoidaSector1_UPPCP', '28.58966084,77.30998866']\n",
    "location_df.loc[len(location_df)] = ['NoidaSector125_UPPCP', '28.54492244,77.32281108']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act_preds = data.loc[id_delhi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot = pd.read_csv('/scratch/ab9738/pollution_img/code/Annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot['filename'] = df_annot['filename'].str[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot = df_annot.set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act_preds['pred'] = preds_delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap = df_act_preds.set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = df_annot['closest_monitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap = df_ap.merge(df_cm, on='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap = df_ap.groupby('closest_monitor').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ap.to_csv('pollution_map_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df_ap['ppm']-df_ap['pred']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(df_ap['ppm']-df_ap['pred'])<50).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
